{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7mSb9wuwWzl518+nJ9pkb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LSTM сети"],"metadata":{"id":"qzHEEtdr2fp3"}},{"cell_type":"markdown","source":["# 1. Определение:\n","\n"],"metadata":{"id":"67rV31z92lDd"}},{"cell_type":"markdown","source":["LSTM (Long Short-Term Memory) - это тип рекуррентных нейронных сетей (RNN), которые были разработаны для эффективной работы с последовательными или временными данными. LSTM сети способны улавливать зависимости в длинных последовательностях данных и сохранять информацию о прошлых событиях для принятия решений."],"metadata":{"id":"nOYEnZxG23KJ"}},{"cell_type":"markdown","source":["Основная идея LSTM состоит в использовании специальных механизмов, называемых \"воротами\" (гейтами), которые регулируют поток информации внутри сети. LSTM сеть состоит из нескольких LSTM блоков, каждый из которых имеет следующие компоненты:\n","\n","## **Входной вектор:** \n","Принимает входные данные для текущего временного шага.\n","\n","## **Скрытое состояние (hidden state):**\n","Хранит информацию о предыдущих временных шагах и передается через время. Он может быть рассмотрен как \"память\" сети.\n","\n","## **Ячейка памяти (cell state):**\n","Хранит информацию о долгосрочных зависимостях в данных. Она может добавлять или удалять информацию, используя специальные ворота.\n","\n","## **Ворота:**\n","\n","* Ворота забывания (Forget Gate): Решает, какую информацию следует забыть из ячейки памяти.\n","* Ворота входа (Input Gate): Решает, какую новую информацию следует добавить в ячейку памяти.\n","* Ворота вывода (Output Gate): Решает, какую информацию следует выходить из скрытого состояния.\n","\n","В каждом временном шаге LSTM блок принимает входные данные и текущее скрытое состояние, а затем обновляет ячейку памяти и скрытое состояние на основе входных данных и предыдущего состояния. Это позволяет LSTM сети эффективно улавливать долгосрочные зависимости в данных."],"metadata":{"id":"r2CIj3HlYIyk"}},{"cell_type":"markdown","source":["# 2. Особенности:"],"metadata":{"id":"1PhCibs923Ho"}},{"cell_type":"markdown","source":["Ячейки памяти LSTM сетей имеют способность запоминать и сохранять информацию на долгое время, что позволяет модели обрабатывать долгосрочные зависимости в данных.\n","LSTM сети обладают внутренней структурой, которая позволяет им контролировать поток информации, регулировать обновление и удаление информации из памяти, а также выбирать, какую информацию передавать на выход.\n","LSTM сети могут работать с переменной длиной последовательностей данных и могут эффективно обрабатывать различные типы данных, такие как текст, аудио, видео и временные ряды."],"metadata":{"id":"DdBTFIaq23FM"}},{"cell_type":"markdown","source":["# 3. Достоинства:"],"metadata":{"id":"3Y91mvTm23C0"}},{"cell_type":"markdown","source":["LSTM сети обладают способностью к обработке долгосрочных зависимостей, что делает их особенно полезными для задач, где необходимо анализировать или генерировать последовательности с долгосрочными зависимостями.\n","Они позволяют эффективно работать с переменной длиной последовательностей данных и могут учитывать контекстную информацию из предыдущих шагов."],"metadata":{"id":"3oMIychG23Ab"}},{"cell_type":"markdown","source":["# 4. Недостатки:"],"metadata":{"id":"_xkY2yHO229b"}},{"cell_type":"markdown","source":["LSTM сети могут быть сложны в обучении и требуют большого количества данных для достижения хороших результатов.\n","Увеличение глубины LSTM сети может привести к проблеме исчезающего градиента -- во время обучения нейронной сети, градиенты (производные) вычисляются и используются для обновления весов нейронов. Однако, при прохождении градиентов через множество слоев, особенно глубоких, производные могут сильно уменьшаться по мере распространения назад по сети. Это означает, что веса первых слоев практически не обновляются, и эти слои не могут эффективно учиться.\n","\n","Таким образом, проблема исчезающего градиента заключается в том, что градиенты \"исчезают\" или становятся очень маленькими по мере распространения назад через глубокие слои сети. Это может приводить к тому, что сеть не способна обучиться сложным зависимостям в данных и дает низкую производительность."],"metadata":{"id":"rXzZJRGM226q"}},{"cell_type":"markdown","source":["# 5. Практическое применение:"],"metadata":{"id":"Lx3nPSWl2233"}},{"cell_type":"markdown","source":["LSTM сети широко используются в области обработки естественного языка (Natural Language Processing, NLP) для задач, таких как машинный перевод, генерация текста, анализ тональности и распознавание речи.\n","Они также применяются в области компьютерного зрения для задач, таких как распознавание объектов, сегментация изображений и генерация описаний изображений.\n","LSTM сети могут быть использованы для анализа временных рядов, прогнозирования временных данных и управления временными процессами."],"metadata":{"id":"ybq94AdF22w-"}},{"cell_type":"markdown","source":["# 6. Практическая часть"],"metadata":{"id":"iNid3GaYnGFi"}},{"cell_type":"code","source":["sequences = []\n","n = 0.0\n","\n","for _ in range(40):\n","    sequence = [round(n * (n / 2) + n, 2)]\n","    m = n\n","\n","    for _ in range(4):\n","        m += 0.1\n","        sequence.append(round(m * (m / 2) + m, 2))\n","    \n","    sequences.append(sequence)\n","    n += 0.1\n","\n","for sequence in sequences:\n","    print(sequence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qyYl9qXNWlDY","executionInfo":{"status":"ok","timestamp":1684574587913,"user_tz":-180,"elapsed":295,"user":{"displayName":"Михаил Ильин","userId":"04782454965296287833"}},"outputId":"d19e5c31-2940-4783-a353-29612ea9c5a6"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.0, 0.11, 0.22, 0.35, 0.48]\n","[0.11, 0.22, 0.35, 0.48, 0.62]\n","[0.22, 0.35, 0.48, 0.62, 0.78]\n","[0.35, 0.48, 0.62, 0.78, 0.94]\n","[0.48, 0.62, 0.78, 0.94, 1.12]\n","[0.62, 0.78, 0.94, 1.12, 1.3]\n","[0.78, 0.94, 1.12, 1.3, 1.5]\n","[0.94, 1.12, 1.3, 1.5, 1.7]\n","[1.12, 1.3, 1.5, 1.7, 1.92]\n","[1.3, 1.5, 1.7, 1.92, 2.15]\n","[1.5, 1.7, 1.92, 2.15, 2.38]\n","[1.7, 1.92, 2.15, 2.38, 2.63]\n","[1.92, 2.15, 2.38, 2.63, 2.88]\n","[2.15, 2.38, 2.63, 2.88, 3.15]\n","[2.38, 2.63, 2.88, 3.15, 3.42]\n","[2.63, 2.88, 3.15, 3.42, 3.71]\n","[2.88, 3.15, 3.42, 3.71, 4.0]\n","[3.15, 3.42, 3.71, 4.0, 4.31]\n","[3.42, 3.71, 4.0, 4.31, 4.62]\n","[3.71, 4.0, 4.31, 4.62, 4.95]\n","[4.0, 4.31, 4.62, 4.95, 5.28]\n","[4.31, 4.62, 4.95, 5.28, 5.63]\n","[4.62, 4.95, 5.28, 5.63, 5.98]\n","[4.95, 5.28, 5.63, 5.98, 6.35]\n","[5.28, 5.63, 5.98, 6.35, 6.72]\n","[5.63, 5.98, 6.35, 6.72, 7.11]\n","[5.98, 6.35, 6.72, 7.11, 7.5]\n","[6.35, 6.72, 7.11, 7.5, 7.91]\n","[6.72, 7.11, 7.5, 7.91, 8.32]\n","[7.11, 7.5, 7.91, 8.32, 8.75]\n","[7.5, 7.91, 8.32, 8.75, 9.18]\n","[7.91, 8.32, 8.75, 9.18, 9.63]\n","[8.32, 8.75, 9.18, 9.63, 10.08]\n","[8.75, 9.18, 9.63, 10.08, 10.55]\n","[9.18, 9.63, 10.08, 10.55, 11.02]\n","[9.63, 10.08, 10.55, 11.02, 11.51]\n","[10.08, 10.55, 11.02, 11.51, 12.0]\n","[10.55, 11.02, 11.51, 12.0, 12.51]\n","[11.02, 11.51, 12.0, 12.51, 13.02]\n","[11.51, 12.0, 12.51, 13.02, 13.55]\n"]}]},{"cell_type":"code","execution_count":91,"metadata":{"id":"yy6FfQnRkr2q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684576770896,"user_tz":-180,"elapsed":14248,"user":{"displayName":"Михаил Ильин","userId":"04782454965296287833"}},"outputId":"791ceca8-dc5e-4754-cf73-9f614f810200"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","40/40 - 2s - loss: 35.0208 - 2s/epoch - 45ms/step\n","Epoch 2/100\n","40/40 - 0s - loss: 13.6293 - 98ms/epoch - 2ms/step\n","Epoch 3/100\n","40/40 - 0s - loss: 5.5142 - 93ms/epoch - 2ms/step\n","Epoch 4/100\n","40/40 - 0s - loss: 2.9008 - 107ms/epoch - 3ms/step\n","Epoch 5/100\n","40/40 - 0s - loss: 1.6609 - 97ms/epoch - 2ms/step\n","Epoch 6/100\n","40/40 - 0s - loss: 1.0275 - 94ms/epoch - 2ms/step\n","Epoch 7/100\n","40/40 - 0s - loss: 0.7412 - 101ms/epoch - 3ms/step\n","Epoch 8/100\n","40/40 - 0s - loss: 0.5571 - 118ms/epoch - 3ms/step\n","Epoch 9/100\n","40/40 - 0s - loss: 0.4772 - 121ms/epoch - 3ms/step\n","Epoch 10/100\n","40/40 - 0s - loss: 0.3407 - 128ms/epoch - 3ms/step\n","Epoch 11/100\n","40/40 - 0s - loss: 0.2893 - 135ms/epoch - 3ms/step\n","Epoch 12/100\n","40/40 - 0s - loss: 0.2005 - 135ms/epoch - 3ms/step\n","Epoch 13/100\n","40/40 - 0s - loss: 0.1409 - 140ms/epoch - 3ms/step\n","Epoch 14/100\n","40/40 - 0s - loss: 0.1045 - 137ms/epoch - 3ms/step\n","Epoch 15/100\n","40/40 - 0s - loss: 0.1251 - 137ms/epoch - 3ms/step\n","Epoch 16/100\n","40/40 - 0s - loss: 0.0798 - 134ms/epoch - 3ms/step\n","Epoch 17/100\n","40/40 - 0s - loss: 0.0528 - 137ms/epoch - 3ms/step\n","Epoch 18/100\n","40/40 - 0s - loss: 0.0440 - 130ms/epoch - 3ms/step\n","Epoch 19/100\n","40/40 - 0s - loss: 0.0434 - 125ms/epoch - 3ms/step\n","Epoch 20/100\n","40/40 - 0s - loss: 0.0366 - 146ms/epoch - 4ms/step\n","Epoch 21/100\n","40/40 - 0s - loss: 0.0299 - 160ms/epoch - 4ms/step\n","Epoch 22/100\n","40/40 - 0s - loss: 0.0324 - 152ms/epoch - 4ms/step\n","Epoch 23/100\n","40/40 - 0s - loss: 0.0329 - 149ms/epoch - 4ms/step\n","Epoch 24/100\n","40/40 - 0s - loss: 0.0385 - 157ms/epoch - 4ms/step\n","Epoch 25/100\n","40/40 - 0s - loss: 0.0352 - 154ms/epoch - 4ms/step\n","Epoch 26/100\n","40/40 - 0s - loss: 0.0256 - 159ms/epoch - 4ms/step\n","Epoch 27/100\n","40/40 - 0s - loss: 0.0211 - 140ms/epoch - 4ms/step\n","Epoch 28/100\n","40/40 - 0s - loss: 0.0345 - 139ms/epoch - 3ms/step\n","Epoch 29/100\n","40/40 - 0s - loss: 0.0163 - 134ms/epoch - 3ms/step\n","Epoch 30/100\n","40/40 - 0s - loss: 0.0198 - 135ms/epoch - 3ms/step\n","Epoch 31/100\n","40/40 - 0s - loss: 0.0199 - 138ms/epoch - 3ms/step\n","Epoch 32/100\n","40/40 - 0s - loss: 0.0198 - 106ms/epoch - 3ms/step\n","Epoch 33/100\n","40/40 - 0s - loss: 0.0172 - 92ms/epoch - 2ms/step\n","Epoch 34/100\n","40/40 - 0s - loss: 0.0117 - 91ms/epoch - 2ms/step\n","Epoch 35/100\n","40/40 - 0s - loss: 0.0619 - 100ms/epoch - 2ms/step\n","Epoch 36/100\n","40/40 - 0s - loss: 0.0444 - 95ms/epoch - 2ms/step\n","Epoch 37/100\n","40/40 - 0s - loss: 0.0299 - 89ms/epoch - 2ms/step\n","Epoch 38/100\n","40/40 - 0s - loss: 0.0255 - 94ms/epoch - 2ms/step\n","Epoch 39/100\n","40/40 - 0s - loss: 0.0361 - 97ms/epoch - 2ms/step\n","Epoch 40/100\n","40/40 - 0s - loss: 0.0253 - 104ms/epoch - 3ms/step\n","Epoch 41/100\n","40/40 - 0s - loss: 0.0265 - 97ms/epoch - 2ms/step\n","Epoch 42/100\n","40/40 - 0s - loss: 0.0099 - 90ms/epoch - 2ms/step\n","Epoch 43/100\n","40/40 - 0s - loss: 0.0093 - 97ms/epoch - 2ms/step\n","Epoch 44/100\n","40/40 - 0s - loss: 0.0095 - 88ms/epoch - 2ms/step\n","Epoch 45/100\n","40/40 - 0s - loss: 0.0074 - 90ms/epoch - 2ms/step\n","Epoch 46/100\n","40/40 - 0s - loss: 0.0093 - 90ms/epoch - 2ms/step\n","Epoch 47/100\n","40/40 - 0s - loss: 0.0094 - 97ms/epoch - 2ms/step\n","Epoch 48/100\n","40/40 - 0s - loss: 0.0098 - 88ms/epoch - 2ms/step\n","Epoch 49/100\n","40/40 - 0s - loss: 0.0063 - 100ms/epoch - 3ms/step\n","Epoch 50/100\n","40/40 - 0s - loss: 0.0095 - 89ms/epoch - 2ms/step\n","Epoch 51/100\n","40/40 - 0s - loss: 0.0081 - 96ms/epoch - 2ms/step\n","Epoch 52/100\n","40/40 - 0s - loss: 0.0102 - 92ms/epoch - 2ms/step\n","Epoch 53/100\n","40/40 - 0s - loss: 0.0115 - 85ms/epoch - 2ms/step\n","Epoch 54/100\n","40/40 - 0s - loss: 0.0088 - 92ms/epoch - 2ms/step\n","Epoch 55/100\n","40/40 - 0s - loss: 0.0164 - 96ms/epoch - 2ms/step\n","Epoch 56/100\n","40/40 - 0s - loss: 0.0168 - 93ms/epoch - 2ms/step\n","Epoch 57/100\n","40/40 - 0s - loss: 0.0060 - 93ms/epoch - 2ms/step\n","Epoch 58/100\n","40/40 - 0s - loss: 0.0057 - 94ms/epoch - 2ms/step\n","Epoch 59/100\n","40/40 - 0s - loss: 0.0092 - 86ms/epoch - 2ms/step\n","Epoch 60/100\n","40/40 - 0s - loss: 0.0113 - 86ms/epoch - 2ms/step\n","Epoch 61/100\n","40/40 - 0s - loss: 0.0159 - 91ms/epoch - 2ms/step\n","Epoch 62/100\n","40/40 - 0s - loss: 0.0067 - 95ms/epoch - 2ms/step\n","Epoch 63/100\n","40/40 - 0s - loss: 0.0098 - 89ms/epoch - 2ms/step\n","Epoch 64/100\n","40/40 - 0s - loss: 0.0467 - 97ms/epoch - 2ms/step\n","Epoch 65/100\n","40/40 - 0s - loss: 0.0371 - 92ms/epoch - 2ms/step\n","Epoch 66/100\n","40/40 - 0s - loss: 0.0103 - 90ms/epoch - 2ms/step\n","Epoch 67/100\n","40/40 - 0s - loss: 0.0060 - 90ms/epoch - 2ms/step\n","Epoch 68/100\n","40/40 - 0s - loss: 0.0096 - 90ms/epoch - 2ms/step\n","Epoch 69/100\n","40/40 - 0s - loss: 0.0081 - 90ms/epoch - 2ms/step\n","Epoch 70/100\n","40/40 - 0s - loss: 0.0046 - 85ms/epoch - 2ms/step\n","Epoch 71/100\n","40/40 - 0s - loss: 0.0091 - 85ms/epoch - 2ms/step\n","Epoch 72/100\n","40/40 - 0s - loss: 0.0033 - 85ms/epoch - 2ms/step\n","Epoch 73/100\n","40/40 - 0s - loss: 0.0045 - 99ms/epoch - 2ms/step\n","Epoch 74/100\n","40/40 - 0s - loss: 0.0039 - 93ms/epoch - 2ms/step\n","Epoch 75/100\n","40/40 - 0s - loss: 0.0156 - 89ms/epoch - 2ms/step\n","Epoch 76/100\n","40/40 - 0s - loss: 0.0033 - 99ms/epoch - 2ms/step\n","Epoch 77/100\n","40/40 - 0s - loss: 0.0111 - 96ms/epoch - 2ms/step\n","Epoch 78/100\n","40/40 - 0s - loss: 0.0084 - 89ms/epoch - 2ms/step\n","Epoch 79/100\n","40/40 - 0s - loss: 0.0181 - 97ms/epoch - 2ms/step\n","Epoch 80/100\n","40/40 - 0s - loss: 0.0086 - 90ms/epoch - 2ms/step\n","Epoch 81/100\n","40/40 - 0s - loss: 0.0164 - 90ms/epoch - 2ms/step\n","Epoch 82/100\n","40/40 - 0s - loss: 0.0139 - 96ms/epoch - 2ms/step\n","Epoch 83/100\n","40/40 - 0s - loss: 0.0186 - 86ms/epoch - 2ms/step\n","Epoch 84/100\n","40/40 - 0s - loss: 0.0097 - 94ms/epoch - 2ms/step\n","Epoch 85/100\n","40/40 - 0s - loss: 0.0039 - 111ms/epoch - 3ms/step\n","Epoch 86/100\n","40/40 - 0s - loss: 0.0044 - 104ms/epoch - 3ms/step\n","Epoch 87/100\n","40/40 - 0s - loss: 0.0049 - 93ms/epoch - 2ms/step\n","Epoch 88/100\n","40/40 - 0s - loss: 0.0044 - 97ms/epoch - 2ms/step\n","Epoch 89/100\n","40/40 - 0s - loss: 0.0095 - 93ms/epoch - 2ms/step\n","Epoch 90/100\n","40/40 - 0s - loss: 0.0049 - 87ms/epoch - 2ms/step\n","Epoch 91/100\n","40/40 - 0s - loss: 0.0046 - 89ms/epoch - 2ms/step\n","Epoch 92/100\n","40/40 - 0s - loss: 0.0149 - 88ms/epoch - 2ms/step\n","Epoch 93/100\n","40/40 - 0s - loss: 0.0238 - 96ms/epoch - 2ms/step\n","Epoch 94/100\n","40/40 - 0s - loss: 0.0997 - 96ms/epoch - 2ms/step\n","Epoch 95/100\n","40/40 - 0s - loss: 0.1348 - 100ms/epoch - 3ms/step\n","Epoch 96/100\n","40/40 - 0s - loss: 0.0324 - 103ms/epoch - 3ms/step\n","Epoch 97/100\n","40/40 - 0s - loss: 0.0028 - 109ms/epoch - 3ms/step\n","Epoch 98/100\n","40/40 - 0s - loss: 0.0104 - 94ms/epoch - 2ms/step\n","Epoch 99/100\n","40/40 - 0s - loss: 0.0047 - 104ms/epoch - 3ms/step\n","Epoch 100/100\n","40/40 - 0s - loss: 0.0036 - 94ms/epoch - 2ms/step\n","\n","\n","1/1 [==============================] - 0s 433ms/step\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","import numpy as np\n","\n","# Создание примера данных для обучения LSTM\n","data = sequences\n","data = np.array(data)\n","\n","# Разделение данных на входные и выходные последовательности\n","X = data[:, :4]  # входные последовательности\n","y = data[:, 4]   # выходная последовательность\n","\n","# Преобразование данных в требуемый формат для LSTM\n","X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n","\n","# Создание модели LSTM\n","model = Sequential()\n","model.add(LSTM(50, input_shape=(4, 1)))\n","model.add(Dense(1))\n","\n","# Компиляция модели\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","\n","# Обучение модели\n","model.fit(X, y, epochs=100, batch_size=1, verbose=2)\n","\n","# Пример использования обученной модели для предсказания\n","test_sequences = []\n","n = 1\n","\n","for _ in range(10):\n","    test_sequence = [round(n * (n / 2) + n, 2)]\n","    m = n\n","\n","    for _ in range(3):\n","        m += 0.1\n","        test_sequence.append(round(m * (m / 2) + m, 2))\n","    \n","    test_sequences.append(test_sequence)\n","    n += 0.1\n","\n","print(\"\\n\")\n","\n","test_data = test_sequences\n","test_data = np.array(test_data)\n","test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], 1))\n","predictions = model.predict(test_data)"]},{"cell_type":"code","source":["# Вывод предсказаний\n","\n","temp = 0\n","\n","for i in range(len(sequences)):\n","    if (sequences[i][4] < predictions[0][0]):\n","        temp += 1\n","\n","# Заголовки столбцов\n","print('-' * 72)\n","print(\"|{:^7s}|{:^30s}|{:^15s}|{:^15s}|\".format(\"№\", \"Input\", \"Prediction\", \"True value\"))\n","print('-' * 72)\n","\n","# Вывод значений\n","for i in range(len(predictions)):\n","    input_sequence = test_sequences[i]\n","    prediction = np.round(predictions[i][0], 2)\n","    true_value = np.round(sequences[temp], 2)\n","    temp += 1\n","    \n","    print(\"|{:^7.0f}|{:^30s}|{:^15.2f}|{:^15.2f}|\".format((i+1), str(input_sequence), prediction, true_value[-1]))\n","print('-' * 72)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMEJ9X0XbhJM","executionInfo":{"status":"ok","timestamp":1684576897691,"user_tz":-180,"elapsed":431,"user":{"displayName":"Михаил Ильин","userId":"04782454965296287833"}},"outputId":"cea57f4c-824b-430e-e6b7-b18302715e3f"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","|   №   |            Input             |  Prediction   |  True value   |\n","------------------------------------------------------------------------\n","|   1   |   [1.5, 1.71, 1.92, 2.15]    |     2.38      |     2.63      |\n","|   2   |   [1.71, 1.92, 2.15, 2.38]   |     2.63      |     2.88      |\n","|   3   |   [1.92, 2.15, 2.38, 2.63]   |     2.88      |     3.15      |\n","|   4   |   [2.15, 2.38, 2.63, 2.88]   |     3.14      |     3.42      |\n","|   5   |   [2.38, 2.63, 2.88, 3.15]   |     3.42      |     3.71      |\n","|   6   |   [2.63, 2.88, 3.15, 3.42]   |     3.70      |     4.00      |\n","|   7   |   [2.88, 3.15, 3.42, 3.71]   |     4.00      |     4.31      |\n","|   8   |   [3.15, 3.42, 3.71, 4.0]    |     4.30      |     4.62      |\n","|   9   |   [3.42, 3.71, 4.0, 4.31]    |     4.61      |     4.95      |\n","|  10   |   [3.71, 4.0, 4.31, 4.62]    |     4.94      |     5.28      |\n","------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["В данном примере входные данные представлены последовательностями чисел data. Каждая последовательность содержит 4 значения, и требуется предсказать пятое значение. Модель LSTM обучается на этих данных, где входные последовательности **X** содержат первые 4 значения каждой последовательности, а выходные значения **y** содержат пятое значение.\n","\n","Далее, модель LSTM создается и компилируется. Она состоит из одного слоя LSTM с 50 нейронами и одного плотного слоя с одним выходным нейроном. Модель обучается на данных с использованием функции потерь 'mean_squared_error' и оптимизатора 'adam' в течение 100 эпох."],"metadata":{"id":"8145-UZtRzTh"}}]}